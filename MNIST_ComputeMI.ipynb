{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import os\n",
    "if not os.path.exists('plots/'):\n",
    "    os.mkdir('plots')\n",
    "\n",
    "from six.moves import cPickle\n",
    "from collections import defaultdict, OrderedDict\n",
    "\n",
    "import numpy as np\n",
    "import tf_keras.backend as K\n",
    "\n",
    "import kde\n",
    "import simplebinmi\n",
    "import matrixRenyi\n",
    "\n",
    "import utils\n",
    "\n",
    "\n",
    "DO_SAVE        = True    # Whether to save plots or just show them\n",
    "DO_LOWER       = False   # Whether to compute lower bounds also\n",
    "DO_BINNED      = True     # Whether to compute MI estimates based on binning\n",
    "DO_MATRIX_BASED = True\n",
    "\n",
    "# Max number of epoch for which to compute mutual information measure\n",
    "MAX_EPOCHS = 2001\n",
    "COLORBAR_MAX_EPOCHS = 2001\n",
    "\n",
    "# Directories from which to load saved layer activity\n",
    "# ARCH = '512-256-128-64-32-16-10-10'\n",
    "ARCH = '10-10-10-10'\n",
    "# ARCH = '512-256'\n",
    "# ARCH = '32-32-32-16-16-16-16'\n",
    "# ARCH = '32-28-24-20-16-12-8-8'\n",
    "# ARCH = '256-10-10-10-10'\n",
    "# ARCH = '512-32-16-16-32-10' \n",
    "# DIR_TEMPLATE = '%%s_%s'%ARCH\n",
    "DIR_TEMPLATE = '%%s_%s'%ARCH\n",
    "# Functions to return upper and lower bounds on entropy of layer activity\n",
    "noise_variance = 0.1             # Added Gaussian noise variance\n",
    "Klayer_activity = K.placeholder(ndim=2)  # Keras placeholder \n",
    "entropy_func_upper = K.function([Klayer_activity,], [kde.entropy_estimator_kl(Klayer_activity, noise_variance),])\n",
    "entropy_func_lower = K.function([Klayer_activity,], [kde.entropy_estimator_bd(Klayer_activity, noise_variance),])\n",
    "\n",
    "\n",
    "# nats to bits conversion factor\n",
    "nats2bits = 1.0/np.log(2) \n",
    "\n",
    "# Save indexes of tests data for each of the output classes\n",
    "bin_size = 0.2\n",
    "trn, tst = utils.get_mnist(training_percent=100)\n",
    "\n",
    "saved_labelixs = {}\n",
    "full = utils.construct_full_dataset(trn, tst)\n",
    "\n",
    "FULL_MI = False\n",
    "if FULL_MI:\n",
    "    labelprobs = np.mean(full.Y, axis=0)\n",
    "    for i in range(10):\n",
    "        saved_labelixs[i] = full.y == i\n",
    "else:\n",
    "    for i in range(10):\n",
    "        saved_labelixs[i] = tst.y == i\n",
    "labelprobs = np.mean(tst.Y, axis=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "PLOT_LAYERS    = None     # Which layers to plot.  If None, all saved layers are plotted \n",
    "\n",
    "# Data structure used to store results\n",
    "measures = OrderedDict()\n",
    "measures['tanh'] = {}\n",
    "# measures['relu'] = {}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compute MI measures\n",
    "-----"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for activation in measures.keys():\n",
    "    # cur_dir = 'rawdata/' + '0.05'+DIR_TEMPLATE % activation\n",
    "    cur_dir = 'rawdata/' + DIR_TEMPLATE % activation\n",
    "    if not os.path.exists(cur_dir):\n",
    "        # print(\"Directory %s not found\" % cur_dir)\n",
    "        continue\n",
    "    # Load files saved during each epoch, and compute MI measures of the activity in that epoch\n",
    "    # print('*** Doing %s ***' % cur_dir)\n",
    "    for epochfile in sorted(os.listdir(cur_dir)):\n",
    "        if not epochfile.startswith('epoch'):\n",
    "            continue\n",
    "            \n",
    "        fname = cur_dir + \"/\" + epochfile\n",
    "        with open(fname, 'rb') as f:\n",
    "            d = cPickle.load(f)\n",
    "        epoch = d['epoch']\n",
    "        if epoch in measures[activation]: # Skip this epoch if its already been processed\n",
    "            continue                      # this is a trick to allow us to rerun this cell multiple times)\n",
    "            \n",
    "        if epoch > MAX_EPOCHS:\n",
    "            continue\n",
    "\n",
    "        print(\"Doing\", fname)\n",
    "        \n",
    "        num_layers = len(d['data']['activity_tst'])\n",
    "\n",
    "        if PLOT_LAYERS is None:\n",
    "            PLOT_LAYERS = []\n",
    "            for lndx in range(num_layers):\n",
    "                # if d['data']['activity_tst'][lndx].shape[1] < 200 and lndx != num_layers - 1:\n",
    "                PLOT_LAYERS.append(lndx)\n",
    "       \n",
    "        cepochdata = defaultdict(list)\n",
    "\n",
    "        for lndx in range(num_layers):\n",
    "                \n",
    "            # only use the test data\n",
    "            activity = d['data']['activity_tst'][lndx][60000:]\n",
    "            DO_KDE = True\n",
    "            if DO_KDE:\n",
    "                if lndx == num_layers-1:    \n",
    "                    activity = activity * 2\n",
    "                # Compute marginal entropies\n",
    "                h_upper = entropy_func_upper([activity,])[0]\n",
    "                if DO_LOWER:\n",
    "                    h_lower = entropy_func_lower([activity,])[0]\n",
    "                    \n",
    "                # # Layer activity given input. This is simply the entropy of the Gaussian noise\n",
    "                hM_given_X = kde.kde_condentropy(activity, noise_variance)\n",
    "                \n",
    "                # Compute conditional entropies of layer activity given output\n",
    "                hM_given_Y_upper=0.\n",
    "                for i in range(10):\n",
    "                    hcond_upper = entropy_func_upper([activity[saved_labelixs[i],:],])[0]\n",
    "                    hM_given_Y_upper += labelprobs[i] * hcond_upper\n",
    "                  \n",
    "                if DO_LOWER:\n",
    "                    hM_given_Y_lower=0.\n",
    "                    for i in range(10):\n",
    "                        hcond_lower = entropy_func_lower([activity[saved_labelixs[i],:],])[0]\n",
    "                        hM_given_Y_lower += labelprobs[i] * hcond_lower\n",
    "                        \n",
    "                cepochdata['MI_XM_upper'].append( nats2bits * (h_upper - hM_given_X) )\n",
    "                cepochdata['MI_YM_upper'].append( nats2bits * (h_upper - hM_given_Y_upper) )\n",
    "                cepochdata['H_M_upper'  ].append( nats2bits * h_upper )\n",
    "\n",
    "            if DO_LOWER:  # Compute lower bounds\n",
    "                cepochdata['MI_XM_lower'].append( nats2bits * (h_lower - hM_given_X) )\n",
    "                cepochdata['MI_YM_lower'].append( nats2bits * (h_lower - hM_given_Y_lower) )\n",
    "                cepochdata['H_M_lower'  ].append( nats2bits * h_lower )\n",
    "            \n",
    "            if DO_BINNED: # Compute binner estimates\n",
    "                # if lndx == num_layers-1:\n",
    "                #     binxm, binym = simplebinmi.bin_calc_information2(saved_labelixs, activity, bin_size/2)\n",
    "                # else:\n",
    "                binxm, binym = simplebinmi.bin_calc_information2(saved_labelixs, activity, bin_size)\n",
    "                cepochdata['MI_XM_bin'].append( nats2bits * binxm )\n",
    "                cepochdata['MI_YM_bin'].append( nats2bits * binym )\n",
    "                \n",
    "            if DO_MATRIX_BASED:\n",
    "                alpha = 1.0001\n",
    "                batch_size = 256\n",
    "                activity = (activity + noise_variance).astype(np.float64)\n",
    "                iterations = activity.shape[0]//batch_size\n",
    "      \n",
    "                Hm = matrixRenyi.renyi_entropy(activity, alpha=alpha, batch_size=batch_size)\n",
    "                Hym =matrixRenyi.conditional_entropy(activity, tst.Y, alpha=alpha, batch_size=batch_size, tsty=tst.y)\n",
    "                # Hxm = matrixRenyi.joint_entropy(activity, tst.X.astype(np.float64), alpha=alpha,batch_size=batch_size)\n",
    "                # Hym = matrixRenyi.joint_entropy(activity, tst.Y.astype(np.float64), alpha=alpha,batch_size=batch_size)\n",
    "                binxm = Hm\n",
    "                binym = Hm - Hym\n",
    "                cepochdata['MI_XM_matrix'].append(binxm )\n",
    "                cepochdata['MI_YM_matrix'].append(binym )\n",
    "                cepochdata['MI_HM_matrix'].append(Hm)\n",
    "        measures[activation][epoch] = cepochdata\n",
    "print(\"DONE!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save MI values\n",
    "\n",
    "import pickle\n",
    "with open(f\"MIs/{ARCH}_MIs.pickle\", \"wb\") as f:\n",
    "    pickle.dump(measures, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot Infoplane Visualization\n",
    "----"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import matplotlib.cm as cm\n",
    "from mpl_toolkits.axes_grid1 import make_axes_locatable\n",
    "import seaborn as sns\n",
    "\n",
    "import matplotlib.gridspec as gridspec\n",
    "sns.set_style('darkgrid')\n",
    "max_epoch = max( (max(vals.keys()) if len(vals) else 0) for vals in measures.values())\n",
    "sm = plt.cm.ScalarMappable(cmap='gnuplot', norm=plt.Normalize(vmin=0, vmax=COLORBAR_MAX_EPOCHS))\n",
    "sm.set_array([])\n",
    "from mpl_toolkits.axes_grid1 import make_axes_locatable\n",
    "\n",
    "# fig=plt.figure(figsize=(10,8))\n",
    "infoplane_measure = \"matrix\"\n",
    "# PLOT_LAYERS = [0,1,2,3,4]\n",
    "fig, ax = plt.subplots(figsize=(12, 8))\n",
    "\n",
    "\n",
    "for actndx, (activation, vals) in enumerate(measures.items()):\n",
    "    epochs = sorted(vals.keys())\n",
    "    if not len(epochs):\n",
    "        continue\n",
    "    # plt.subplot(1,2,actndx+1)    \n",
    "    for epoch in epochs:\n",
    "        c = sm.to_rgba(epoch)\n",
    "        xmvals = np.array(vals[epoch]['MI_XM_'+infoplane_measure])[PLOT_LAYERS]\n",
    "        ymvals = np.array(vals[epoch]['MI_YM_'+infoplane_measure])[PLOT_LAYERS]\n",
    "\n",
    "        plt.plot(xmvals, ymvals, c=c, alpha=0.1, zorder=1)\n",
    "        plt.scatter(xmvals, ymvals, s=40, facecolors=[c for _ in PLOT_LAYERS], edgecolor='none', zorder=2)\n",
    "    \n",
    "    # plt.ylim([0, 3.5])\n",
    "    # plt.xlim([0, 14])\n",
    "    plt.xlabel('I(X;T)', fontsize=20)\n",
    "    plt.ylabel('I(Y;T)', fontsize=20)\n",
    "    plt.xticks(fontsize=18)\n",
    "    plt.yticks(fontsize=18)\n",
    "    divider = make_axes_locatable(ax)\n",
    "\n",
    "    cax = divider.append_axes(\"right\", size=\"5%\", pad=0.25)\n",
    "    cbar = plt.colorbar(sm, cax=cax)\n",
    "    # cax.yaxis.set_ticks([])  # Remove ticks\n",
    "    cbar.set_label('epochs', fontsize=20)\n",
    "    cax.yaxis.set_ticks_position('right')  # Make ticks appear on the left side\n",
    "    \n",
    "\n",
    "    plt.tight_layout()\n",
    "\n",
    "DO_SAVE =True\n",
    "if DO_SAVE:\n",
    "    plt.savefig('plots/' + ('infoplane_1'+ARCH+\"_\"+activation+\"_\"+infoplane_measure),bbox_inches='tight')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
