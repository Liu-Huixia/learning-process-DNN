{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import os\n",
    "if not os.path.exists('plots/'):\n",
    "    os.mkdir('plots')\n",
    "import pickle\n",
    "from six.moves import cPickle\n",
    "from collections import defaultdict, OrderedDict\n",
    "\n",
    "import numpy as np\n",
    "import keras\n",
    "import tf_keras.backend as K\n",
    "from IPython.display import clear_output\n",
    "\n",
    "import kde\n",
    "import simplebinmi\n",
    "import matrixRenyi\n",
    "\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.gridspec as gridspec\n",
    "import seaborn as sns\n",
    "sns.set_style('darkgrid')\n",
    "\n",
    "import utils\n",
    "\n",
    "# load data network was trained on\n",
    "trn, tst = utils.get_IB_data('2017_12_21_16_51_3_275766')\n",
    "\n",
    "\n",
    "# calc MI for train and test. Save_activations must have been run with cfg['FULL_MI'] = True\n",
    "FULL_MI = True\n",
    "\n",
    "# Which measure to plot\n",
    "infoplane_measure = 'upper'\n",
    "infoplane_measure = 'bin'\n",
    "\n",
    "DO_MATRIX_BASED = True\n",
    "DO_SAVE        = True    # Whether to save plots or just show them\n",
    "DO_LOWER       = (infoplane_measure == 'lower')   # Whether to compute lower bounds also\n",
    "DO_BINNED      = True     # Whether to compute MI estimates based on binning\n",
    "DO_BINNED_2    = (infoplane_measure == 'bin2')    # compute MI estimates base on Riv\n",
    "MAX_EPOCHS = 10001      # Max number of epoch for which to compute mutual information measure\n",
    "NUM_LABELS = 2\n",
    "# MAX_EPOCHS = 1000\n",
    "COLORBAR_MAX_EPOCHS = 10001\n",
    "\n",
    "# Directories from which to load saved layer activity\n",
    "ARCH = '10-7-5-4-3'\n",
    "# ARCH = '10-8-6-4-2'\n",
    "\n",
    "\n",
    "DIR_TEMPLATE = '%%s_%s'%ARCH\n",
    "\n",
    "# Functions to return upper and lower bounds on entropy of layer activity\n",
    "noise_variance = 1e-1                # Added Gaussian noise variance\n",
    "binsize =0.07       # binsize \n",
    "num_of_bins = 30\n",
    "# size of bins for binning method\n",
    "Klayer_activity = K.placeholder(ndim=2)  # Keras placeholder \n",
    "entropy_func_upper = K.function([Klayer_activity,], [kde.entropy_estimator_kl(Klayer_activity, noise_variance),])\n",
    "entropy_func_lower = K.function([Klayer_activity,], [kde.entropy_estimator_bd(Klayer_activity, noise_variance),])\n",
    "\n",
    "# nats to bits conversion factor\n",
    "nats2bits = 1.0/np.log(2) \n",
    "\n",
    "# Save indexes of tests data for each of the output classes\n",
    "saved_labelixs = {}\n",
    "\n",
    "y = tst.y\n",
    "Y = tst.Y\n",
    "if FULL_MI:\n",
    "    full = utils.construct_full_dataset(trn,tst)\n",
    "    y = full.y\n",
    "    Y = full.Y\n",
    "\n",
    "for i in range(NUM_LABELS):\n",
    "    saved_labelixs[i] = y == i  \n",
    "\n",
    "labelprobs = np.mean(Y, axis=0)  # the probability of y==0 or y==1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "PLOT_LAYERS    = None     # Which layers to plot.  If None, all saved layers are plotted \n",
    "# Data structure used to store results\n",
    "measures = OrderedDict()\n",
    "measures['tanh'] = {}\n",
    "# measures['relu'] = {}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compute MI measures\n",
    "-----"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Directory rawdata/tanh_10-7-5-4-3 not found\n"
     ]
    }
   ],
   "source": [
    "for activation in measures.keys():\n",
    "    cur_dir = 'rawdata/' + DIR_TEMPLATE % activation\n",
    "    if not os.path.exists(cur_dir):\n",
    "        print(\"Directory %s not found\" % cur_dir)\n",
    "        continue\n",
    "        \n",
    "    # Load files saved during each epoch, and compute MI measures of the activity in that epoch\n",
    "    print('*** Doing %s ***' % cur_dir)\n",
    "    for epochfile in sorted(os.listdir(cur_dir)):\n",
    "        if not epochfile.startswith('epoch'):\n",
    "            continue\n",
    "            \n",
    "        fname = cur_dir + \"/\" + epochfile\n",
    "        with open(fname, 'rb') as f:\n",
    "            d = cPickle.load(f)\n",
    "\n",
    "        epoch = d['epoch']\n",
    "        if epoch in measures[activation]: # Skip this epoch if its already been processed\n",
    "            continue                      # this is a trick to allow us to rerun this cell multiple times)\n",
    "            \n",
    "        if epoch > MAX_EPOCHS:\n",
    "            continue\n",
    "\n",
    "        print(\"Doing\", fname)\n",
    "        \n",
    "        num_layers = len(d['data']['activity_tst'])\n",
    "\n",
    "        if PLOT_LAYERS is None:\n",
    "            PLOT_LAYERS = []\n",
    "            for lndx in range(num_layers):\n",
    "                #if d['data']['activity_tst'][lndx].shape[1] < 200 and lndx != num_layers - 1:\n",
    "                PLOT_LAYERS.append(lndx)\n",
    "                \n",
    "        cepochdata = defaultdict(list)\n",
    "        for lndx in range(num_layers):\n",
    "            activity = d['data']['activity_tst'][lndx]\n",
    "            # Compute marginal entropies\n",
    "            h_upper = entropy_func_upper([activity,])[0]\n",
    "            # h_upper = kde.entropy_estimator_kl(activity, noise_variance)\n",
    "            if DO_LOWER:\n",
    "                h_lower = entropy_func_lower([activity,])[0]\n",
    "                \n",
    "            # Layer activity given input. This is simply the entropy of the Gaussian noise\n",
    "            hM_given_X = kde.kde_condentropy(activity, noise_variance)\n",
    "\n",
    "            # Compute conditional entropies of layer activity given output\n",
    "            hM_given_Y_upper=0.\n",
    "            for i in range(NUM_LABELS):\n",
    "                hcond_upper = entropy_func_upper([activity[saved_labelixs[i],:],])[0]\n",
    "                # hcond_upper = kde.entropy_estimator_kl(activity[saved_labelixs[i],:], noise_variance)\n",
    "\n",
    "                hM_given_Y_upper += labelprobs[i] * hcond_upper\n",
    "                \n",
    "            if DO_LOWER:\n",
    "                hM_given_Y_lower=0.\n",
    "                for i in range(NUM_LABELS):\n",
    "                    hcond_lower = entropy_func_lower([activity[saved_labelixs[i],:],])[0]\n",
    "                    hM_given_Y_lower += labelprobs[i] * hcond_lower\n",
    "                \n",
    "            cepochdata['MI_XM_upper'].append( nats2bits * (h_upper - hM_given_X) )\n",
    "            cepochdata['MI_YM_upper'].append( nats2bits * (h_upper - hM_given_Y_upper) )\n",
    "            cepochdata['H_M_upper'  ].append( nats2bits * h_upper )\n",
    "            # pstr = 'upper: MI(X;M)=%0.3f, MI(Y;M)=%0.3f' % (cepochdata['MI_XM_upper'][-1], cepochdata['MI_YM_upper'][-1])\n",
    "            if DO_LOWER:  # Compute lower bounds\n",
    "                cepochdata['MI_XM_lower'].append( nats2bits * (h_lower - hM_given_X) )\n",
    "                cepochdata['MI_YM_lower'].append( nats2bits * (h_lower - hM_given_Y_lower) )\n",
    "                cepochdata['H_M_lower'  ].append( nats2bits * h_lower )\n",
    "                # pstr += ' | lower: MI(X;M)=%0.3f, MI(Y;M)=%0.3f' % (cepochdata['MI_XM_lower'][-1], cepochdata['MI_YM_lower'][-1])\n",
    "            if DO_BINNED: # Compute binned estimates\n",
    "                if lndx == num_layers-1:\n",
    "                    binxm, binym = simplebinmi.bin_calc_information2(saved_labelixs, activity, binsize/2)\n",
    "                else:\n",
    "                    binxm, binym = simplebinmi.bin_calc_information2(saved_labelixs, activity, binsize)\n",
    "                cepochdata['MI_XM_bin'].append( nats2bits * binxm )\n",
    "                cepochdata['MI_YM_bin'].append( nats2bits * binym )\n",
    "                # pstr += ' | bin: MI(X;M)=%0.3f, MI(Y;M)=%0.3f' % (cepochdata['MI_XM_bin'][-1], cepochdata['MI_YM_bin'][-1])\n",
    "            # if DO_MATRIX_BASED:\n",
    "            \n",
    "\n",
    "        measures[activation][epoch] = cepochdata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the MI results\n",
    "with open(f\"MIs/{ARCH}_MIs.pickle\", \"wb\") as f:\n",
    "    pickle.dump(measures, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot Infoplane Visualization\n",
    "----"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "# import matplotlib.gridspec as gridspec\n",
    "import seaborn as sns\n",
    "\n",
    "infoplane_measure = 'bin'\n",
    "\n",
    "max_epoch = max( (max(vals.keys()) if len(vals) else 0) for vals in measures.values())\n",
    "sm = plt.cm.ScalarMappable(cmap='gnuplot', norm=plt.Normalize(vmin=0, vmax=COLORBAR_MAX_EPOCHS))\n",
    "sm._A = []\n",
    "\n",
    "fig=plt.figure(figsize=(12,10))\n",
    "for actndx, (activation, vals) in enumerate(measures.items()):\n",
    "    \n",
    "    epochs = sorted(vals.keys())\n",
    "    if not len(epochs):\n",
    "        continue\n",
    "    # plt.subplot(1,2,actndx+1)    \n",
    "    for epoch in epochs:\n",
    "        c = sm.to_rgba(epoch)\n",
    "        xmvals = np.array(vals[epoch]['MI_XM_'+infoplane_measure])[PLOT_LAYERS]\n",
    "        ymvals = np.array(vals[epoch]['MI_YM_'+infoplane_measure])[PLOT_LAYERS]\n",
    "        plt.plot(xmvals, ymvals, c=c, alpha=0.1, zorder=1)\n",
    "        plt.scatter(xmvals, ymvals, s=50, facecolors=[c for _ in PLOT_LAYERS], edgecolor='none', zorder=2)\n",
    "\n",
    "    plt.xlabel('I(X;T)',fontsize=20)\n",
    "    plt.ylabel('I(Y;T)',fontsize=20)\n",
    "    plt.title(activation,fontsize=20)\n",
    "    \n",
    "cbaxes = fig.add_axes([1.0, 0.125, 0.03, 0.8]) \n",
    "plt.colorbar(sm, label='Epoch', cax=cbaxes)\n",
    "plt.tight_layout()\n",
    "\n",
    "\n",
    "DO_SAVE = True\n",
    "if DO_SAVE:\n",
    "    plt.savefig('plots/' + DIR_TEMPLATE % ('infoplane_'+activation+'_'+infoplane_measure),bbox_inches='tight')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
